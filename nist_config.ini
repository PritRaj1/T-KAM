[MIX_PRIOR]
layer_widths = 20, 41
spline_degree = 3
base_activation = gelu
spline_function = B-spline
grid_size = 40
grid_update_ratio = 0.05
grid_range = 0,1 
ε_scale = 0.1
μ_scale = 1
σ_base = 1
σ_spline = 1
init_η = 1
η_trainable = true
π_0 = uniform

[KAN_LIKELIHOOD]
expert_widths = 41, 82
spline_degree = 3
base_activation = gelu
spline_function = B-spline
grid_size = 40
grid_update_ratio = 0.05
grid_range = 0,1 
ε_scale = 0.1
μ_scale = 1
σ_base = 1
σ_spline = 1
init_η = 1
η_trainable = true
generator_noise_var = 0.1
generator_variance = 1
likelihood_model = bernoulli
output_activation = sigmoid
resampler = residual

[GRID_UPDATING]
update_prior_grid = false
update_llhood_grid = true
num_grid_updating_samples = 100
grid_update_frequency = 50
grid_update_decay = 0.999

[MALA]
use_langevin = false
step_size = 0.001
noise_var = 1
iters = 50

[THERMODYNAMIC_INTEGRATION]
num_temps = 10
p_start = 4
p_end = 0.25
num_cycles = 4
num_langevin_per_temp = 5

[TRAINING]
batch_size = 32
MC_expectation_sample_size = 64
N_train = 6400
N_test = 32
num_generated_samples = 200
batch_size_for_gen = 100
N_epochs = 10
use_gpu = true
dataset = MNIST
update_grid = true
verbose = true
contrastive_divergence_training = true
resampling_threshold_factor = 0.1
quantization = FP32

[OPTIMIZER]
type = adam
learning_rate = 0.002
l-bfgs_memory = 100

[LINE_SEARCH]
type = morethuente
c_1 = 1e-4
c_2 = 0.9
rho = 0.5